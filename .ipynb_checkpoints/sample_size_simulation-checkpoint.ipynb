{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e9ff6f1-1b7a-4c1f-a210-b60f21dea234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31c3fad6-9fe1-46ea-a86c-eced5a69e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reshape the matrix:\n",
    "def gen_dissimilarity_matrix(data, size=[20, 20]):\n",
    "\n",
    "    dissimilarity_matrix = np.zeros(size)\n",
    "    ctr = 0\n",
    "    for i in range(size[0]):\n",
    "        for j in range(i+1, size[0]):\n",
    "            if ctr >= data.shape[0]:\n",
    "                break\n",
    "            dissimilarity_matrix[i, j] = data[ctr]\n",
    "            dissimilarity_matrix[j, i] = data[ctr]\n",
    "            ctr += 1\n",
    "    return dissimilarity_matrix\n",
    "\n",
    "\n",
    "# Function to simulate ratings and calculate ICC\n",
    "def simulate_icc(initial_raters, items=210, target_icc=0.7, inter_rater_noise=2, seed=123):\n",
    "    np.random.seed(seed)  # For reproducibility\n",
    "    \n",
    "    # Generate simulated ratings\n",
    "    # Create ground truth similarity:\n",
    "    sim_ground_truth = np.random.normal(loc=10, scale=4, size=(items))\n",
    "    # Create single subject data:\n",
    "    ratings = np.zeros([items, initial_raters])\n",
    "    for i in range(initial_raters):\n",
    "        subject_noise = np.random.normal(loc=0, scale=inter_rater_noise, size=(items))\n",
    "        ratings[:, i] = sim_ground_truth + subject_noise\n",
    "    \n",
    "    # Convert the numpy array to a DataFrame, which is needed for pingouin's ICC function\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(ratings)\n",
    "    \n",
    "    # Reshape the DataFrame for pingouin ICC calculation: long format with 'rater' and 'items' as columns\n",
    "    df_melt = pd.melt(df.reset_index(), id_vars='index', value_vars=df.columns)\n",
    "    df_melt.columns = ['items', 'raters', 'ratings']\n",
    "    \n",
    "    # Calculate ICC\n",
    "    icc = pg.intraclass_corr(data=df_melt, targets='items', raters='raters', ratings='ratings').round(3)\n",
    "    \n",
    "    # Extract the ICC value\n",
    "    icc_value = icc.loc[icc['Type'] == 'ICC2', 'ICC'].values[0]\n",
    "    pval = icc.loc[icc['Type'] == 'ICC2', 'pval'].values[0]\n",
    "    \n",
    "    return icc_value, pval, sim_ground_truth, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "86f63dff-1814-40e4-a3ef-ec507015c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "n_stim = 3\n",
    "n_pairs = int((n_stim * n_stim) / 2)\n",
    "initial_raters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11] # Starting point for the number of raters\n",
    "inter_rater_noise =  np.arange(0.5, 10, 0.5)\n",
    "icc_results = np.zeros([len(inter_rater_noise), len(initial_raters)])\n",
    "pvals = np.zeros([len(inter_rater_noise), len(initial_raters)])\n",
    "corr_res = np.zeros([len(inter_rater_noise), len(initial_raters)])\n",
    "\n",
    "target_icc = 0.7    # Target ICC value you're aiming for\n",
    "for ii, noise in enumerate(inter_rater_noise):\n",
    "    for i, n_rater in enumerate(initial_raters):\n",
    "        icc_value, pval, sim_ground_truth, ratings = simulate_icc(n_rater, target_icc=target_icc, inter_rater_noise=noise, items=n_pairs)\n",
    "        pvals[ii, i] = pval\n",
    "        icc_results[ii, i] = icc_value\n",
    "        true_dissimilarity_matrix = gen_dissimilarity_matrix(sim_ground_truth, size=[n_stim, n_stim])\n",
    "        obs_dissimilarity_mat = np.array([gen_dissimilarity_matrix(ratings[:, iii], size=[n_stim, n_stim]) for iii in (range(ratings.shape[1]))])\n",
    "        corr, _ = pearsonr(sim_ground_truth, np.mean(ratings, axis=1))\n",
    "        corr_res[ii, i] = corr\n",
    "        # fig, ax = plt.subplots(1, 2)\n",
    "        # ax[0].imshow(true_dissimilarity_matrix)\n",
    "        # ax[1].imshow(np.mean(obs_dissimilarity_mat, axis=0))\n",
    "        # ax[0].set_ylabel(\"Stim 1\")\n",
    "        # ax[0].set_xlabel(\"Stim 2\")\n",
    "        # ax[1].set_ylabel(\"Stim 1\")\n",
    "        # ax[1].set_xlabel(\"Stim 2\")\n",
    "        # fig.suptitle('Pearsons correlation: %.3f' % corr)\n",
    "        # plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fb638-f230-4e0d-83e1-fc56906f49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the simulation:\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "print(icc_results.shape)\n",
    "img1 = axs[0, 0].imshow(icc_results, extent=[initial_raters[0], initial_raters[-1], inter_rater_noise[0], inter_rater_noise[-1]], aspect=\"auto\", origin='lower')\n",
    "axs[0, 0].set_title(\"Intra class correlation coefficient\")\n",
    "axs[0, 0].set_xlabel(\"N raters\")\n",
    "axs[0, 0].set_ylabel(\"Inter raters noise\")\n",
    "plt.colorbar(img1)\n",
    "img2 = axs[0, 1].imshow(np.where(pvals < 0.05, np.nan, pvals), extent=[initial_raters[0], initial_raters[-1], inter_rater_noise[0], inter_rater_noise[-1]], aspect=\"auto\", origin='lower')\n",
    "axs[0, 1].set_title(\"P values\")\n",
    "plt.colorbar(img2)\n",
    "img3 = axs[1, 0].imshow(corr_res, extent=[initial_raters[0], initial_raters[-1], inter_rater_noise[0], inter_rater_noise[-1]], aspect=\"auto\", origin='lower')\n",
    "axs[1, 0].set_title(\"Correlation to ground truth\")\n",
    "plt.colorbar(img3)\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "axs[1, 1].plot(x, norm.pdf(x, 0, inter_rater_noise[0]), label=f'sigma = {inter_rater_noise[0]}')\n",
    "axs[1, 1].plot(x, norm.pdf(x, 0, inter_rater_noise[1]), label=f'sigma = {inter_rater_noise[1]}')\n",
    "axs[1, 1].plot(x, norm.pdf(x, 0, inter_rater_noise[2]), label=f'sigma = {inter_rater_noise[2]}')\n",
    "axs[1, 1].plot(x, norm.pdf(x, 0, inter_rater_noise[3]), label=f'sigma = {inter_rater_noise[3]}')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].set_title(\"Inter-rater noise distributions\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116eb50-af7c-4a3b-94d4-c9aec29de41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b1ac1c35-af9b-493b-befc-f6c8f9f79987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ,\n",
       "       6.5, 7. , 7.5, 8. , 8.5, 9. , 9.5])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.5, 10, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
